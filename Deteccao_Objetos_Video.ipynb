{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgWNlCHTlb4OA+07GQ8lYG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmersonGodoi/Deteccao_Objetos_Video/blob/main/Deteccao_Objetos_Video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh04EPAUW07l"
      },
      "outputs": [],
      "source": [
        "#Etapa 1 - Importando as bibliotecas\n",
        "import cv2\n",
        "print(cv2.__version__)\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import zipfile\n",
        "print(cv2.__version__)\n",
        "\n",
        "#Etapa 2 - Conectando com o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#Etapa 3 - Carregando os arquivos do modelo treinado\n",
        "path =  '/content/gdrive/MyDrive/Detecção de Objetos com YOLO, Darknet, OpenCV e Python/modelo_YOLOv4.zip'\n",
        "zip_object = zipfile.ZipFile(file=path, mode=\"r\")\n",
        "zip_object.extractall(\"./\")\n",
        "zip_object.close()\n",
        "\n",
        "labels_path = os.path.sep.join(['/content/cfg', \"coco.names\"])\n",
        "LABELS = open(labels_path).read().strip().split(\"\\n\")\n",
        "\n",
        "weights_path = os.path.sep.join(['/content/', \"yolov4.weights\"])\n",
        "config_path = os.path.sep.join(['/content/cfg', \"yolov4.cfg\"])\n",
        "\n",
        "net = cv2.dnn.readNet(config_path, weights_path)\n",
        "\n",
        "#Etapa 4 - Definindo mais configurações para a detecção\n",
        "np.random.seed(42)\n",
        "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")\n",
        "\n",
        "ln = net.getLayerNames()\n",
        "print(\"Todas as camadas (layers):\")\n",
        "print(ln)\n",
        "print(\"Total: \"+ str(len(ln)))\n",
        "print(\"Camadas de saída: \")\n",
        "print(net.getUnconnectedOutLayers())\n",
        "ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "print(ln)\n",
        "\n",
        "#Etapa 5 - Criando as funções para detecção e processamento do video\n",
        "#Função para exibir imagens no Colab\n",
        "def mostrar(img):\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(16, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()\n",
        "#Construindo o blob da imagem\n",
        "def blob_imagem(net, imagem, mostrar_texto=True):\n",
        "  inicio = time.time()\n",
        "  blob = cv2.dnn.blobFromImage(imagem, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
        "  net.setInput(blob)\n",
        "  layerOutputs = net.forward(ln)\n",
        "  termino = time.time()\n",
        "  if mostrar_texto:\n",
        "    print(\"YOLO levou {:.2f} segundos\".format(termino - inicio))\n",
        "  return net, imagem, layerOutputs\n",
        "#Realizando a detecção\n",
        "def deteccoes(detection, _threshold, caixas, confiancas, IDclasses):\n",
        "  scores = detection[5:]\n",
        "  classeID = np.argmax(scores)\n",
        "  confianca = scores[classeID]\n",
        "\n",
        "  if confianca > _threshold:\n",
        "      caixa = detection[0:4] * np.array([W, H, W, H])\n",
        "      (centerX, centerY, width, height) = caixa.astype(\"int\")\n",
        "\n",
        "      x = int(centerX - (width / 2))\n",
        "      y = int(centerY - (height / 2))\n",
        "\n",
        "      caixas.append([x, y, int(width), int(height)])\n",
        "      confiancas.append(float(confianca))\n",
        "      IDclasses.append(classeID)\n",
        "\n",
        "  return caixas, confiancas, IDclasses\n",
        "#Mostrando o resultado da detecção no video\n",
        "def funcoes_imagem(imagem, i, confiancas, caixas, COLORS, LABELS, mostrar_texto=True):\n",
        "  (x, y) = (caixas[i][0], caixas[i][1])\n",
        "  (w, h) = (caixas[i][2], caixas[i][3])\n",
        "\n",
        "  cor = [int(c) for c in COLORS[IDclasses[i]]]\n",
        "  cv2.rectangle(imagem, (x, y), (x + w, y + h), cor, 2)\n",
        "  texto = \"{}: {:.4f}\".format(LABELS[IDclasses[i]], confiancas[i])\n",
        "  if mostrar_texto:\n",
        "    print(\"> \" + texto)\n",
        "    print(x,y,w,h)\n",
        "  cv2.putText(imagem, texto, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, cor, 2)\n",
        "\n",
        "  return imagem,x,y,w,h\n",
        "\n",
        "#Etapa 6 - Carregando o vídeo onde será feita a detecção\n",
        "!cp /content/gdrive/MyDrive/Detecção\\ de\\ Objetos\\ com\\ YOLO,\\ Darknet,\\ OpenCV\\ e\\ Python/videos/video_pessoas01.mp4 ./\n",
        "#Lendo o arquivo de vídeo com o OpenCV\n",
        "arquivo_video = 'video_pessoas01.mp4'\n",
        "cap = cv2.VideoCapture(arquivo_video)\n",
        "conectado, video = cap.read()\n",
        "\n",
        "conectado\n",
        "\n",
        "video.shape\n",
        "\n",
        "video_largura = video.shape[1]\n",
        "video_altura = video.shape[0]\n",
        "video_largura, video_altura\n",
        "\n",
        "#Etapa 7 - Redimensionamento do tamanho do video\n",
        "def redimensionar(largura, altura, largura_maxima = 600):\n",
        "  if (largura > largura_maxima):\n",
        "    proporcao = largura / altura\n",
        "    video_largura = largura_maxima\n",
        "    video_altura = int(video_largura / proporcao)\n",
        "  else:\n",
        "    video_largura = largura\n",
        "    video_altura = altura\n",
        "\n",
        "  return video_largura, video_altura\n",
        "\n",
        "video_largura, video_altura = redimensionar(video.shape[1], video.shape[0])\n",
        "print(video_largura,video_altura)\n",
        "\n",
        "#Etapa 8 - Definindo as configurações do vídeo\n",
        "nome_arquivo = 'resultado.avi'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID') # MP4V\n",
        "\n",
        "fps = 24 #video mais lento mudar para 20\n",
        "\n",
        "saida_video = cv2.VideoWriter(nome_arquivo, fourcc, fps, (video_largura, video_altura))\n",
        "\n",
        "#Etapa 9 - Definindo as variáveis\n",
        "threshold = 0.5\n",
        "threshold_NMS = 0.3\n",
        "fonte_pequena, fonte_media = 0.4, 0.6\n",
        "fonte = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "amostras_exibir = 20\n",
        "amostra_atual = 0\n",
        "\n",
        "#Etapa 10 - Processamento do vídeo e exibição do resultado\n",
        "while (cv2.waitKey(1) < 0):\n",
        "  conectado, frame = cap.read()\n",
        "  if not conectado:\n",
        "    break\n",
        "  t = time.time()\n",
        "  frame = cv2.resize(frame, (video_largura, video_altura))\n",
        "  try:\n",
        "    (H, W) = frame.shape[:2]\n",
        "  except:\n",
        "    print('Erro')\n",
        "    continue\n",
        "\n",
        "  imagem_cp = frame.copy()\n",
        "  net, frame, layerOutputs = blob_imagem(net, frame)\n",
        "  caixas = []\n",
        "  confiancas = []\n",
        "  IDclasses = []\n",
        "\n",
        "  for output in layerOutputs:\n",
        "    for detection in output:\n",
        "      caixas, confiancas, IDclasses = deteccoes(detection, threshold, caixas, confiancas, IDclasses)\n",
        "\n",
        "  objs = cv2.dnn.NMSBoxes(caixas, confiancas, threshold, threshold_NMS)\n",
        "\n",
        "  if len(objs) > 0:\n",
        "    for i in objs.flatten():\n",
        "      frame, x, y, w, h = funcoes_imagem(frame, i, confiancas, caixas, COLORS, LABELS, mostrar_texto=False)\n",
        "      objeto = imagem_cp[y:y + h, x:x + w]\n",
        "\n",
        "  cv2.putText(frame, \" frame processado em {:.2f} segundos\".format(time.time() - t),\n",
        "              (20, video_altura-20), fonte, fonte_pequena, (250, 250, 250), 0, lineType=cv2.LINE_AA)\n",
        "\n",
        "  if amostra_atual <= amostras_exibir:\n",
        "    cv2_imshow(frame)\n",
        "    amostra_atual += 1\n",
        "\n",
        "  saida_video.write(frame)\n",
        "\n",
        "print('Terminou')\n",
        "saida_video.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "#Exportando Video\n",
        "!du -h resultado.avi\n",
        "\n",
        "!cp ./resultado.avi /content/gdrive/MyDrive/Detecção\\ de\\ Objetos\\ com\\ YOLO,\\ Darknet,\\ OpenCV\\ e\\ Python/videos/resultado3.avi\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}